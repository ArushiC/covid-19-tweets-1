{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Twitter API authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_api_key = os.environ[\"TWITTER_CONSUMER_API_KEY\"]\n",
    "consumer_api_secret = os.environ[\"TWITTER_CONSUMER_API_SECRET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tw.OAuthHandler(consumer_api_key, consumer_api_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tweets query\n",
    "\n",
    "### 3.1. Define the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_words = \"#covid19 -filter:retweets\"\n",
    "date_since = \"2020-03-01\"\n",
    "# Collect tweets\n",
    "tweets = tw.Cursor(api.search,\n",
    "              q=search_words,\n",
    "              lang=\"en\",\n",
    "              since=date_since).items(7500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Retreive the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2780it [01:27, 31.60it/s]\n"
     ]
    }
   ],
   "source": [
    "tweets_copy = []\n",
    "for tweet in tqdm(tweets):\n",
    "    tweets_copy.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new tweets retrieved: 2780\n"
     ]
    }
   ],
   "source": [
    "print(f\"new tweets retrieved: {len(tweets_copy)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Populate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2780/2780 [00:10<00:00, 264.00it/s]\n"
     ]
    }
   ],
   "source": [
    "tweets_df = pd.DataFrame()\n",
    "for tweet in tqdm(tweets_copy):\n",
    "    hashtags = []\n",
    "    try:\n",
    "        for hashtag in tweet.entities[\"hashtags\"]:\n",
    "            hashtags.append(hashtag[\"text\"])\n",
    "    except:\n",
    "        pass\n",
    "    tweets_df = tweets_df.append(pd.DataFrame({'user_name': tweet.user.name, \n",
    "                                               'user_location': tweet.user.location,\\\n",
    "                                               'user_description': tweet.user.description,\n",
    "                                               'user_created': tweet.user.created_at,\n",
    "                                               'user_followers': tweet.user.followers_count,\n",
    "                                               'user_friends': tweet.user.friends_count,\n",
    "                                               'user_favourites': tweet.user.favourites_count,\n",
    "                                               'user_verified': tweet.user.verified,\n",
    "                                               'date': tweet.created_at,\n",
    "                                               'text': tweet.text, \n",
    "                                               'hashtags': [hashtags if hashtags else None],\n",
    "                                               'source': tweet.source,\n",
    "                                               'is_retweet': tweet.retweeted}, index=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "      <th>is_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Totally Toytastic</td>\n",
       "      <td>South Molton, North Devon, UK</td>\n",
       "      <td>Totally Toytastic Ltd is an online toy store w...</td>\n",
       "      <td>2013-01-16 10:51:09</td>\n",
       "      <td>10104</td>\n",
       "      <td>11019</td>\n",
       "      <td>5975</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-07-29 16:30:35</td>\n",
       "      <td>Fun Reusable Face Coverings for Adults and Kid...</td>\n",
       "      <td>[facemask, face]</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DAILY SABAH</td>\n",
       "      <td>Istanbul</td>\n",
       "      <td>Turkey‚Äôs top English newspaper, providing the ...</td>\n",
       "      <td>2013-12-05 19:08:07</td>\n",
       "      <td>485787</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-29 16:30:35</td>\n",
       "      <td>New Orleans Pelicans to take on Utah Jazz as N...</td>\n",
       "      <td>[COVID19]</td>\n",
       "      <td>Hootsuite Inc.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peggy Smedley</td>\n",
       "      <td>Carol Stream, IL</td>\n",
       "      <td>Tech-People-Connector: Podcast doer, influence...</td>\n",
       "      <td>2009-07-20 15:57:05</td>\n",
       "      <td>29731</td>\n",
       "      <td>3907</td>\n",
       "      <td>1268</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-07-29 16:30:34</td>\n",
       "      <td>.@BW_Research &amp;amp; .@e2org show some improvem...</td>\n",
       "      <td>[energy]</td>\n",
       "      <td>Hootsuite Inc.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D.E. Sciulli üéö</td>\n",
       "      <td>The Laurel Highlands, PA, USA</td>\n",
       "      <td>Lib, Dem &amp; Atheist‚ö°Ô∏èTrump HATERüëé ‚ÄúI know it‚Äôs ...</td>\n",
       "      <td>2014-07-28 23:25:09</td>\n",
       "      <td>11973</td>\n",
       "      <td>12128</td>\n",
       "      <td>13524</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-07-29 16:30:34</td>\n",
       "      <td>Maybe if a few high profile Republicans suffer...</td>\n",
       "      <td>[Covid19]</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>McKnight's LTC News</td>\n",
       "      <td>Northbrook, IL</td>\n",
       "      <td>An independent news resource for those in the ...</td>\n",
       "      <td>2009-06-29 19:48:13</td>\n",
       "      <td>10146</td>\n",
       "      <td>889</td>\n",
       "      <td>894</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-07-29 16:30:34</td>\n",
       "      <td>In her latest, @DrEl gathers advice from LTC p...</td>\n",
       "      <td>[COVID19]</td>\n",
       "      <td>Hootsuite Inc.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_name                  user_location  \\\n",
       "0    Totally Toytastic  South Molton, North Devon, UK   \n",
       "0          DAILY SABAH                       Istanbul   \n",
       "0        Peggy Smedley               Carol Stream, IL   \n",
       "0       D.E. Sciulli üéö  The Laurel Highlands, PA, USA   \n",
       "0  McKnight's LTC News                 Northbrook, IL   \n",
       "\n",
       "                                    user_description        user_created  \\\n",
       "0  Totally Toytastic Ltd is an online toy store w... 2013-01-16 10:51:09   \n",
       "0  Turkey‚Äôs top English newspaper, providing the ... 2013-12-05 19:08:07   \n",
       "0  Tech-People-Connector: Podcast doer, influence... 2009-07-20 15:57:05   \n",
       "0  Lib, Dem & Atheist‚ö°Ô∏èTrump HATERüëé ‚ÄúI know it‚Äôs ... 2014-07-28 23:25:09   \n",
       "0  An independent news resource for those in the ... 2009-06-29 19:48:13   \n",
       "\n",
       "   user_followers  user_friends  user_favourites  user_verified  \\\n",
       "0           10104         11019             5975          False   \n",
       "0          485787             2                0           True   \n",
       "0           29731          3907             1268          False   \n",
       "0           11973         12128            13524          False   \n",
       "0           10146           889              894          False   \n",
       "\n",
       "                 date                                               text  \\\n",
       "0 2020-07-29 16:30:35  Fun Reusable Face Coverings for Adults and Kid...   \n",
       "0 2020-07-29 16:30:35  New Orleans Pelicans to take on Utah Jazz as N...   \n",
       "0 2020-07-29 16:30:34  .@BW_Research &amp; .@e2org show some improvem...   \n",
       "0 2020-07-29 16:30:34  Maybe if a few high profile Republicans suffer...   \n",
       "0 2020-07-29 16:30:34  In her latest, @DrEl gathers advice from LTC p...   \n",
       "\n",
       "           hashtags              source  is_retweet  \n",
       "0  [facemask, face]           Instagram       False  \n",
       "0         [COVID19]      Hootsuite Inc.       False  \n",
       "0          [energy]      Hootsuite Inc.       False  \n",
       "0         [Covid19]  Twitter for iPhone       False  \n",
       "0         [COVID19]      Hootsuite Inc.       False  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save the data\n",
    "\n",
    "### 5.1. Read past data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past tweets: (39676, 13)\n"
     ]
    }
   ],
   "source": [
    "tweets_old_df = pd.read_csv(\"covid19_tweets.csv\")\n",
    "print(f\"past tweets: {tweets_old_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Merge past and present data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new tweets: 2780 past tweets: 39676 all tweets: 42456\n"
     ]
    }
   ],
   "source": [
    "tweets_all_df = pd.concat([tweets_old_df, tweets_df], axis=0)\n",
    "print(f\"new tweets: {tweets_df.shape[0]} past tweets: {tweets_old_df.shape[0]} all tweets: {tweets_all_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all tweets: (42456, 13)\n"
     ]
    }
   ],
   "source": [
    "tweets_all_df.drop_duplicates(subset = [\"user_name\", \"date\", \"text\"], inplace=True)\n",
    "print(f\"all tweets: {tweets_all_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4. Export the updated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_all_df.to_csv(\"covid19_tweets.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
